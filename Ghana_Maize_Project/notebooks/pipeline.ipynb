{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2464e450",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5268a3",
   "metadata": {},
   "source": [
    "# IMPORTANT Install dependencies safely\n",
    "\n",
    "Run ONLY the next cell (Install Dependencies). This cell installs required Python packages without running the pipeline.\n",
    "\n",
    "Do NOT run other cells after installation unless you intend to re-run the full pipeline (which may regenerate CSVs or download external data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3c5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment Ready.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GHANA MAIZE YIELD PREDICTION PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "# 1. SETUP & IMPORTS\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Utilities\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Ensure directories exist\n",
    "for d in [\"../data/raw\", \"../data/processed\", \"../data/final\", \"../models\", \"../reports\"]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Environment Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2e78a",
   "metadata": {},
   "source": [
    "# helper functiions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da80462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def clean_district_name(name):\n",
    "    \"\"\"Standardizes district names for consistent merging.\"\"\"\n",
    "    if pd.isna(name): return \"\"\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r'\\s*\\([^)]*\\)', '', name)  # Remove content in brackets\n",
    "    name = name.replace(' municipal', '').replace(' muni', '').replace(' district', '')\n",
    "    name = name.replace(' metropolitan', '').replace(' metro', '')\n",
    "    name = name.replace('-', ' ')\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name.title()\n",
    "\n",
    "def get_soil_map():\n",
    "    \"\"\"Maps Administrative Regions to Dominant Soil Types.\"\"\"\n",
    "    return {\n",
    "        'Ashanti': 'Forest Ochrosol', 'Brong Ahafo': 'Forest Ochrosol',\n",
    "        'Bono': 'Forest Ochrosol', 'Bono East': 'Forest Ochrosol',\n",
    "        'Ahafo': 'Forest Ochrosol', 'Eastern': 'Forest Ochrosol',\n",
    "        'Western': 'Forest Ochrosol', 'Western North': 'Forest Ochrosol',\n",
    "        'Central': 'Forest Ochrosol', 'Northern': 'Savanna Ochrosol',\n",
    "        'Savannah': 'Savanna Ochrosol', 'North East': 'Savanna Ochrosol',\n",
    "        'Upper East': 'Savanna Ochrosol', 'Upper West': 'Savanna Ochrosol',\n",
    "        'Oti': 'Savanna Ochrosol', 'Greater Accra': 'Coastal Savannah',\n",
    "        'Volta': 'Tropical Black Earth'\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d9321",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7e1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 1: DATA INGESTION ---\n",
      "âœ… Yield Data Loaded: 1681 rows (2010-2016)\n",
      "   -> Imputing 2017-2021 data using National Averages...\n",
      "âš ï¸ Weather file not found. Downloading from NASA (This takes ~5 mins)...\n",
      "âœ… Weather Download Complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. DATA PROCESSING\n",
    "# =============================================================================\n",
    "print(\"\\n--- PHASE 1: DATA INGESTION ---\")\n",
    "\n",
    "# A. LOAD RAW YIELD DATA\n",
    "# We look for the file in data/raw or the root folder\n",
    "raw_path = \"../data/raw/maize_yield.csv\"\n",
    "if not os.path.exists(raw_path) and os.path.exists(\"maize_yield.csv\"):\n",
    "    raw_path = \"maize_yield.csv\" # Fallback for Colab root\n",
    "\n",
    "if os.path.exists(raw_path):\n",
    "    df_yield = pd.read_csv(raw_path)\n",
    "    # Clean Columns\n",
    "    df_yield.columns = [c.strip().title() for c in df_yield.columns]\n",
    "    \n",
    "    # Identify District Column dynamically\n",
    "    dist_col = next((c for c in df_yield.columns if 'District' in c or 'DISTRICT' in c), None)\n",
    "    if dist_col:\n",
    "        df_yield.rename(columns={dist_col: 'District', 'YEAR': 'Year', 'YIELD': 'Yield'}, inplace=True)\n",
    "        df_yield['District'] = df_yield['District'].apply(clean_district_name)\n",
    "        print(f\"âœ… Yield Data Loaded: {len(df_yield)} rows (2010-2016)\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not find 'District' column in CSV.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"âŒ 'maize_yield.csv' not found. Please upload it to data/raw/\")\n",
    "\n",
    "# B. IMPUTE MISSING YEARS (2017-2021)\n",
    "# We generate new rows using National Averages to capture the PFJ Policy era\n",
    "print(\"   -> Imputing 2017-2021 data using National Averages...\")\n",
    "unique_districts = df_yield['District'].unique()\n",
    "national_avgs = [\n",
    "    {'Year': 2017, 'Yield': 2.04}, {'Year': 2018, 'Yield': 2.25},\n",
    "    {'Year': 2019, 'Yield': 2.53}, {'Year': 2020, 'Yield': 2.58},\n",
    "    {'Year': 2021, 'Yield': 2.53}\n",
    "]\n",
    "new_rows = [{'District': d, 'Year': entry['Year'], 'Yield': entry['Yield']} \n",
    "            for d in unique_districts for entry in national_avgs]\n",
    "df_extended = pd.concat([df_yield[['District', 'Year', 'Yield']], pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# C. GET WEATHER DATA (NASA API)\n",
    "weather_path = \"../data/processed/Step2_Weather_Data.csv\"\n",
    "\n",
    "if os.path.exists(weather_path):\n",
    "    df_weather = pd.read_csv(weather_path)\n",
    "    print(\"âœ… Weather Data Loaded from cache.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Weather file not found. Downloading from NASA (This takes ~5 mins)...\")\n",
    "    geolocator = Nominatim(user_agent=\"ghana_maize_project_v1\")\n",
    "    weather_data = []\n",
    "    base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    \n",
    "    for district in unique_districts:\n",
    "        try:\n",
    "            # Geolocate\n",
    "            loc = geolocator.geocode(f\"{district}, Ghana\", timeout=10)\n",
    "            if loc:\n",
    "                # API Request\n",
    "                params = {\n",
    "                    \"parameters\": \"T2M,PRECTOTCORR,RH2M,ALLSKY_SFC_SW_DWN,GWETTOP\",\n",
    "                    \"community\": \"AG\", \"longitude\": loc.longitude, \"latitude\": loc.latitude,\n",
    "                    \"start\": \"20100101\", \"end\": \"20211231\", \"format\": \"JSON\"\n",
    "                }\n",
    "                resp = requests.get(base_url, params=params)\n",
    "                \n",
    "                if resp.status_code == 200:\n",
    "                    d = resp.json()['properties']['parameter']\n",
    "                    temp_df = pd.DataFrame({\n",
    "                        'Date': pd.to_datetime(list(d['T2M'].keys())),\n",
    "                        'Rainfall': list(d['PRECTOTCORR'].values()),\n",
    "                        'Temperature': list(d['T2M'].values()),\n",
    "                        'Humidity': list(d['RH2M'].values()),\n",
    "                        'Sunlight': list(d['ALLSKY_SFC_SW_DWN'].values()),\n",
    "                        'Soil_Moisture': list(d['GWETTOP'].values()),\n",
    "                        'District': district\n",
    "                    })\n",
    "                    weather_data.append(temp_df)\n",
    "            time.sleep(1) # Be polite to API\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {district}: {e}\")\n",
    "    \n",
    "    if weather_data:\n",
    "        df_weather = pd.concat(weather_data)\n",
    "        # Ensure output directory exists then save to the intended path\n",
    "        os.makedirs(os.path.dirname(weather_path), exist_ok=True)\n",
    "        df_weather.to_csv(weather_path, index=False)\n",
    "        print(\"âœ… Weather Download Complete.\")\n",
    "    else:\n",
    "        raise ValueError(\"âŒ Failed to download weather data.\")\n",
    "\n",
    "# Aggregating Weather (Seasonal: April - August)\n",
    "df_weather['Date'] = pd.to_datetime(df_weather['Date'])\n",
    "df_weather['Month'] = df_weather['Date'].dt.month\n",
    "df_weather['Year'] = df_weather['Date'].dt.year\n",
    "\n",
    "season_weather = df_weather[df_weather['Month'].isin([4, 5, 6, 7, 8])]\n",
    "weather_agg = season_weather.groupby(['District', 'Year']).agg({\n",
    "    'Rainfall': 'sum',\n",
    "    'Temperature': 'mean',\n",
    "    'Humidity': 'mean',\n",
    "    'Sunlight': 'mean',\n",
    "    'Soil_Moisture': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# D. ADD SOIL DATA\n",
    "# If original file had Region, we map it. If not, we default to Forest Ochrosol.\n",
    "if 'Region' in df_yield.columns:\n",
    "    df_soil = df_yield[['District', 'Region']].drop_duplicates()\n",
    "    df_soil['Region'] = df_soil['Region'].str.title().str.strip()\n",
    "    df_soil['Soil_Type'] = df_soil['Region'].map(get_soil_map()).fillna('Forest Ochrosol')\n",
    "else:\n",
    "    df_soil = pd.DataFrame({'District': unique_districts})\n",
    "    df_soil['Soil_Type'] = 'Forest Ochrosol'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95192d1f",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ac0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 2: ENGINEERING ---\n",
      "âœ… Master Dataset Created: (1775, 12)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "print(\"\\n--- PHASE 2: ENGINEERING ---\")\n",
    "\n",
    "# Merge\n",
    "master_df = pd.merge(df_extended, weather_agg, on=['District', 'Year'], how='inner')\n",
    "master_df = pd.merge(master_df, df_soil[['District', 'Soil_Type']], on='District', how='left')\n",
    "\n",
    "# 1. Winsorization (Cap Outliers)\n",
    "master_df['Yield'] = np.where(master_df['Yield'] > 4.0, 4.0, master_df['Yield'])\n",
    "\n",
    "# 2. Add Event Shocks\n",
    "master_df['Pest_Risk'] = np.where(master_df['Year'].isin([2016, 2017]), 1, 0)\n",
    "master_df['PFJ_Policy'] = np.where(master_df['Year'] >= 2017, 1, 0)\n",
    "\n",
    "# 3. Add Lag Features (Crucial Step)\n",
    "master_df.sort_values(['District', 'Year'], inplace=True)\n",
    "master_df['Yield_Lag1'] = master_df.groupby('District')['Yield'].shift(1)\n",
    "\n",
    "# Remove rows with NaN (First year has no history)\n",
    "final_df = master_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Save Master Dataset\n",
    "final_path = \"../data/final/Ghana_Maize_Master_Dataset.csv\"\n",
    "final_df.to_csv(final_path, index=False)\n",
    "print(f\"âœ… Master Dataset Created: {final_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564dd3f",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c093d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 3: TRAINING ENSEMBLE ---\n",
      "ðŸš€ Model Accuracy (R2): 0.899\n",
      "ðŸ“‰ Error Margin (MAE):  0.078 tons/ha\n",
      "ðŸ’¾ Model saved to 'models/maize_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. MODEL TRAINING\n",
    "# =============================================================================\n",
    "print(\"\\n--- PHASE 3: TRAINING ENSEMBLE ---\")\n",
    "\n",
    "X = final_df[['Rainfall', 'Temperature', 'Humidity', 'Sunlight', 'Soil_Moisture', \n",
    "              'Soil_Type', 'Pest_Risk', 'PFJ_Policy', 'Year', 'Yield_Lag1']]\n",
    "y = final_df['Yield']\n",
    "\n",
    "# Pipeline Setup\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['Soil_Type']),\n",
    "    ('num', 'passthrough', [c for c in X.columns if c != 'Soil_Type'])\n",
    "])\n",
    "\n",
    "# Voting Ensemble (Random Forest + Gradient Boosting)\n",
    "ensemble = VotingRegressor([\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ensemble)\n",
    "])\n",
    "\n",
    "# Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸš€ Model Accuracy (R2): {r2:.3f}\")\n",
    "print(f\"ðŸ“‰ Error Margin (MAE):  {mae:.3f} tons/ha\")\n",
    "\n",
    "# Save Model\n",
    "joblib.dump(model_pipeline, \"../models/maize_model.pkl\")\n",
    "print(\"ðŸ’¾ Model saved to 'models/maize_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3321c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Visualizations saved to ../reports/\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. VISUALIZATIONS: Save plots to ../reports\n",
    "# =============================================================================\n",
    "import os\n",
    "os.makedirs(\"../reports\", exist_ok=True)\n",
    "# Set plotting style robustly (fallbacks if style name not available)\n",
    "try:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "except Exception:\n",
    "    try:\n",
    "        sns.set_theme(style='darkgrid')\n",
    "    except Exception:\n",
    "        try:\n",
    "            sns.set_style('darkgrid')\n",
    "        except Exception:\n",
    "            plt.style.use('ggplot')\n",
    "\n",
    "# 1) National average yield trend by Year\n",
    "yr_df = final_df.groupby('Year')['Yield'].mean().reset_index()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(data=yr_df, x='Year', y='Yield', marker='o')\n",
    "plt.title('National Average Maize Yield by Year')\n",
    "plt.ylabel('Yield (tons/ha)')\n",
    "plt.xlabel('Year')\n",
    "plt.savefig('../reports/national_yield_trend.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2) Yield distribution by Soil Type (boxplot)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=final_df, x='Soil_Type', y='Yield')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Yield Distribution by Soil Type')\n",
    "plt.xlabel('Soil Type')\n",
    "plt.ylabel('Yield (tons/ha)')\n",
    "plt.savefig('../reports/yield_by_soil_type.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3) Rainfall (Apr-Aug) vs Yield with regression line\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.regplot(data=final_df, x='Rainfall', y='Yield', scatter_kws={'s':10}, line_kws={'color':'red'})\n",
    "plt.title('Rainfall (Apr-Aug) vs Yield')\n",
    "plt.xlabel('Rainfall (mm)')\n",
    "plt.ylabel('Yield (tons/ha)')\n",
    "plt.savefig('../reports/rainfall_vs_yield.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4) Correlation heatmap among key numeric features\n",
    "num_cols = ['Yield','Rainfall','Temperature','Humidity','Sunlight','Soil_Moisture','Yield_Lag1']\n",
    "corr = final_df[num_cols].corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.savefig('../reports/feature_correlation.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5) Feature importances (attempt to extract from RandomForest in ensemble)\n",
    "try:\n",
    "    reg = model_pipeline.named_steps['regressor']\n",
    "    rf = None\n",
    "    if hasattr(reg, 'estimators_') and len(reg.estimators_)>0:\n",
    "        candidate = reg.estimators_[0]\n",
    "        if isinstance(candidate, tuple):\n",
    "            rf = candidate[1]\n",
    "        else:\n",
    "            rf = candidate\n",
    "\n",
    "    if rf is not None and hasattr(rf, 'feature_importances_'):\n",
    "        importances = rf.feature_importances_\n",
    "        pre = model_pipeline.named_steps['preprocessor']\n",
    "        num_features = [c for c in X.columns if c != 'Soil_Type']\n",
    "        try:\n",
    "            ohe = pre.named_transformers_['cat']\n",
    "            ohe_features = list(ohe.get_feature_names_out(['Soil_Type']))\n",
    "        except Exception:\n",
    "            ohe_features = []\n",
    "        feature_names = num_features + ohe_features\n",
    "        if len(importances) != len(feature_names):\n",
    "            feature_names = [f'F{i}' for i in range(len(importances))]\n",
    "        feat_imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        # Assign hue to 'feature' (avoids palette-without-hue deprecation) and remove legend\n",
    "        ax = sns.barplot(data=feat_imp_df, x='importance', y='feature', hue='feature', dodge=False, palette='viridis')\n",
    "        try:\n",
    "            lg = ax.get_legend()\n",
    "            if lg is not None:\n",
    "                lg.remove()\n",
    "        except Exception:\n",
    "            pass\n",
    "        plt.title('Feature Importances (Random Forest)')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.savefig('../reports/feature_importances.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        print('RandomForest feature importances not available.')\n",
    "except Exception as e:\n",
    "    print('Could not compute feature importances:', e)\n",
    "\n",
    "print('âœ… Visualizations saved to ../reports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8ae4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
