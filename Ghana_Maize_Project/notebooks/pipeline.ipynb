{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22489528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Utilities\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Ensure directories exist\n",
    "for d in [\"../data/raw\", \"../data/processed\", \"../data/final\", \"../models\", \"../reports\"]:\n",
    "    os.makedirs(d, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9539c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_district_name(name):\n",
    "    \"\"\"Standardizes district names for consistent merging.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "\n",
    "    name = str(name).lower()\n",
    "\n",
    "    # Remove text in brackets\n",
    "    name = re.sub(r'\\s*\\([^)]*\\)', '', name)\n",
    "\n",
    "    # Remove common suffixes\n",
    "    suffixes = [\n",
    "        ' municipal', ' muni', ' district',\n",
    "        ' metropolitan', ' metro'\n",
    "    ]\n",
    "    for suffix in suffixes:\n",
    "        name = name.replace(suffix, '')\n",
    "\n",
    "    # Normalize spacing and symbols\n",
    "    name = name.replace('-', ' ')\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    return name.title()\n",
    "\n",
    "\n",
    "def get_soil_map():\n",
    "    \"\"\"Maps Ghana's administrative regions to their dominant soil types.\"\"\"\n",
    "    return {\n",
    "        # Forest zones\n",
    "        'Ashanti': 'Forest Ochrosol',\n",
    "        'Brong Ahafo': 'Forest Ochrosol',\n",
    "        'Bono': 'Forest Ochrosol',\n",
    "        'Bono East': 'Forest Ochrosol',\n",
    "        'Ahafo': 'Forest Ochrosol',\n",
    "        'Eastern': 'Forest Ochrosol',\n",
    "        'Western': 'Forest Ochrosol',\n",
    "        'Western North': 'Forest Ochrosol',\n",
    "        'Central': 'Forest Ochrosol',\n",
    "\n",
    "        # Savanna zones\n",
    "        'Northern': 'Savanna Ochrosol',\n",
    "        'Savannah': 'Savanna Ochrosol',\n",
    "        'North East': 'Savanna Ochrosol',\n",
    "        'Upper East': 'Savanna Ochrosol',\n",
    "        'Upper West': 'Savanna Ochrosol',\n",
    "        'Oti': 'Savanna Ochrosol',\n",
    "\n",
    "        # Coastal & special zones\n",
    "        'Greater Accra': 'Coastal Savannah',\n",
    "        'Volta': 'Tropical Black Earth'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1488a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield Data Loaded: 1681 rows (2010-2016)\n",
      "Imputing 2017-2021 data using National Averages...\n",
      "Weather file not found. Downloading from NASA POWER API...\n",
      "Weather Download Complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A. LOAD RAW YIELD DATA\n",
    "# We look for the file in data/raw or the root folder\n",
    "raw_path = \"../data/raw/maize_yield.csv\"\n",
    "if not os.path.exists(raw_path) and os.path.exists(\"maize_yield.csv\"):\n",
    "    raw_path = \"maize_yield.csv\" # Fallback for Colab root\n",
    "\n",
    "if os.path.exists(raw_path):\n",
    "    df_yield = pd.read_csv(raw_path)\n",
    "    # Clean Columns\n",
    "    df_yield.columns = [c.strip().title() for c in df_yield.columns]\n",
    "    \n",
    "    # Identify District Column dynamically\n",
    "    dist_col = next((c for c in df_yield.columns if 'District' in c or 'DISTRICT' in c), None)\n",
    "    if dist_col:\n",
    "        df_yield.rename(columns={dist_col: 'District', 'YEAR': 'Year', 'YIELD': 'Yield'}, inplace=True)\n",
    "        df_yield['District'] = df_yield['District'].apply(clean_district_name)\n",
    "        print(f\"Yield Data Loaded: {len(df_yield)} rows (2010-2016)\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not find 'District' column in CSV.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"'maize_yield.csv' not found. Please upload it to data/raw/\")\n",
    "\n",
    "# B. IMPUTE MISSING YEARS (2017-2021)\n",
    "# We generate new rows using National Averages to capture the PFJ Policy era\n",
    "print(\"Imputing 2017-2021 data using National Averages...\")\n",
    "unique_districts = df_yield['District'].unique()\n",
    "\n",
    "national_avgs = [\n",
    "    {'Year': 2017, 'Yield': 2.04}, \n",
    "    {'Year': 2018, 'Yield': 2.25},\n",
    "    {'Year': 2019, 'Yield': 2.53}, \n",
    "    {'Year': 2020, 'Yield': 2.58},\n",
    "    {'Year': 2021, 'Yield': 2.53}\n",
    "]\n",
    "new_rows = [{'District': d, 'Year': entry['Year'], 'Yield': entry['Yield']} \n",
    "            for d in unique_districts for entry in national_avgs]\n",
    "df_extended = pd.concat([df_yield[['District', 'Year', 'Yield']], pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# C. GET WEATHER DATA (NASA API)\n",
    "weather_path = \"../data/processed/Weather_Data.csv\"\n",
    "\n",
    "if os.path.exists(weather_path):\n",
    "    df_weather = pd.read_csv(weather_path)\n",
    "    print(\"Weather Data Loaded from cache.\")\n",
    "else:\n",
    "    print(\"Weather file not found. Downloading from NASA POWER API...\")\n",
    "    geolocator = Nominatim(user_agent=\"ghana_maize_project_v1\")\n",
    "    weather_data = []\n",
    "    base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    \n",
    "    for district in unique_districts:\n",
    "        try:\n",
    "            # Geolocate\n",
    "            loc = geolocator.geocode(f\"{district}, Ghana\", timeout=10)\n",
    "            if loc:\n",
    "                # API Request\n",
    "                params = {\n",
    "                    \"parameters\": \"T2M,PRECTOTCORR,RH2M,ALLSKY_SFC_SW_DWN,GWETTOP\",\n",
    "                    \"community\": \"AG\", \"longitude\": loc.longitude, \"latitude\": loc.latitude,\n",
    "                    \"start\": \"20100101\", \"end\": \"20211231\", \"format\": \"JSON\"\n",
    "                }\n",
    "                resp = requests.get(base_url, params=params)\n",
    "                \n",
    "                if resp.status_code == 200:\n",
    "                    d = resp.json()['properties']['parameter']\n",
    "                    temp_df = pd.DataFrame({\n",
    "                        'Date': pd.to_datetime(list(d['T2M'].keys())),\n",
    "                        'Rainfall': list(d['PRECTOTCORR'].values()),\n",
    "                        'Temperature': list(d['T2M'].values()),\n",
    "                        'Humidity': list(d['RH2M'].values()),\n",
    "                        'Sunlight': list(d['ALLSKY_SFC_SW_DWN'].values()),\n",
    "                        'Soil_Moisture': list(d['GWETTOP'].values()),\n",
    "                        'District': district\n",
    "                    })\n",
    "                    weather_data.append(temp_df)\n",
    "            time.sleep(1) # Be polite to API\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {district}: {e}\")\n",
    "    \n",
    "    if weather_data:\n",
    "        df_weather = pd.concat(weather_data)\n",
    "        df_weather.to_csv(weather_path, index=False)\n",
    "        print(\"Weather Download Complete.\")\n",
    "    else:\n",
    "        raise ValueError(\"Failed to download weather data.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09d8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SEASONAL WEATHER AGGREGATION (APRIL–AUGUST)\n",
    "\n",
    "df_weather[\"Date\"] = pd.to_datetime(df_weather[\"Date\"])\n",
    "df_weather[\"Year\"] = df_weather[\"Date\"].dt.year\n",
    "df_weather[\"Month\"] = df_weather[\"Date\"].dt.month\n",
    "\n",
    "season_weather = df_weather[df_weather[\"Month\"].between(4, 8)]\n",
    "\n",
    "weather_agg = (\n",
    "    season_weather\n",
    "    .groupby([\"District\", \"Year\"], as_index=False)\n",
    "    .agg({\n",
    "        \"Rainfall\": \"sum\",\n",
    "        \"Temperature\": \"mean\",\n",
    "        \"Humidity\": \"mean\",\n",
    "        \"Sunlight\": \"mean\",\n",
    "        \"Soil_Moisture\": \"mean\"\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "# ADD SOIL DATA\n",
    "# Map region → dominant soil type\n",
    "\n",
    "if \"Region\" in df_yield.columns:\n",
    "    df_soil = (\n",
    "        df_yield[[\"District\", \"Region\"]]\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            Region=lambda x: x[\"Region\"].str.title().str.strip(),\n",
    "            Soil_Type=lambda x: x[\"Region\"]\n",
    "                .map(get_soil_map())\n",
    "                .fillna(\"Forest Ochrosol\")\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    df_soil = pd.DataFrame({\n",
    "        \"District\": unique_districts,\n",
    "        \"Soil_Type\": \"Forest Ochrosol\"\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b0e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Dataset Created: (1775, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge\n",
    "df = pd.merge(df_extended, weather_agg, on=['District', 'Year'], how='inner')\n",
    "df = pd.merge(df, df_soil[['District', 'Soil_Type']], on='District', how='left')\n",
    "\n",
    "# 1. Winsorization (Cap Outliers)\n",
    "# df['Yield'] = np.where(df['Yield'] > 4.0, 4.0, df['Yield'])\n",
    "# 2. Add Event Shocks\n",
    "df['Pest_Risk'] = np.where(df['Year'].isin([2016, 2017]), 1, 0)\n",
    "df['PFJ_Policy'] = np.where(df['Year'] >= 2017, 1, 0)\n",
    "\n",
    "# 3. Add Lag Features (Crucial Step)\n",
    "df.sort_values(['District', 'Year'], inplace=True)\n",
    "df['Yield_Lag1'] = df.groupby('District')['Yield'].shift(1)\n",
    "# Remove rows with NaN (First year has no history)\n",
    "final_df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Save Master Dataset\n",
    "final_path = \"../data/final/Ghana_Maize.csv\"\n",
    "final_df.to_csv(final_path, index=False)\n",
    "print(f\"Master Dataset Created: {final_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
